"""
å¢å¼ºç‰ˆå‘½ä»¤è¡Œäº¤äº’ç•Œé¢
æ”¯æŒç½‘ç»œæœç´¢åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

import argparse
try:
    import yaml
except ImportError:
    yaml = None
from core.llm_client import OllamaClient
from agents.web_enhanced_agent import WebEnhancedAgent
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config(config_path: str = "config.yaml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if yaml is None:
        return {}
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except:
        return {}


def interactive_mode(agent):
    """äº¤äº’æ¨¡å¼"""
    print(f"\n{'=' * 60}")
    print(f"å¢å¼ºå‹ AI åŠ©æ‰‹ï¼ˆæ”¯æŒç½‘ç»œæœç´¢ï¼‰")
    print(f"{'=' * 60}")
    print("åŠŸèƒ½ï¼š")
    print("  - å›ç­”ä¸€èˆ¬é—®é¢˜")
    print("  - è‡ªåŠ¨æœç´¢æœ€æ–°ä¿¡æ¯")
    print("  - è·å–æŠ€æœ¯èµ„è®¯")
    print(f"{'=' * 60}")
    print("\nå‘½ä»¤ï¼š")
    print("  quit   - é€€å‡ºç¨‹åº")
    print("  clear  - æ¸…ç©ºå¯¹è¯å†å²")
    print("  search - å¼ºåˆ¶æœç´¢æ¨¡å¼")
    print("  news   - è·å–æŠ€æœ¯èµ„è®¯")
    print("  help   - æ˜¾ç¤ºå¸®åŠ©")
    print(f"{'=' * 60}\n")
    
    force_search = False
    
    while True:
        try:
            user_input = input("AI> ").strip()
            
            if not user_input:
                continue
                
            # å‘½ä»¤å¤„ç†
            if user_input.lower() == 'quit':
                print("\nå†è§ï¼ğŸ‘‹")
                break
                
            if user_input.lower() == 'clear':
                agent.llm.clear_history()
                print("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
                
            if user_input.lower() == 'search':
                force_search = not force_search
                status = "å¼€å¯" if force_search else "å…³é—­"
                print(f"âœ… å¼ºåˆ¶æœç´¢æ¨¡å¼å·²{status}")
                continue
                
            if user_input.lower().startswith('news'):
                parts = user_input.split()
                category = parts[1] if len(parts) > 1 else "AI"
                print(f"\nè·å– {category} é¢†åŸŸæœ€æ–°èµ„è®¯...")
                result = agent._get_tech_news(category)
                if result.get("success"):
                    print(result["summary"])
                else:
                    print(f"âŒ {result.get('error')}")
                continue
                
            if user_input.lower() == 'help':
                print("\nå¯ç”¨å‘½ä»¤ï¼š")
                print("  quit   - é€€å‡ºç¨‹åº")
                print("  clear  - æ¸…ç©ºå¯¹è¯å†å²")
                print("  search - åˆ‡æ¢å¼ºåˆ¶æœç´¢æ¨¡å¼")
                print("  news [ç±»åˆ«] - è·å–æŠ€æœ¯èµ„è®¯")
                print("    ç±»åˆ«: AI, Blender, Unity, GameDev")
                print("  help   - æ˜¾ç¤ºå¸®åŠ©")
                print("\næç¤ºï¼š")
                print("  - è¯¢é—®'æœ€æ–°'ã€'2026'ç­‰å…³é”®è¯ä¼šè‡ªåŠ¨è§¦å‘æœç´¢")
                print("  - å¼€å¯å¼ºåˆ¶æœç´¢æ¨¡å¼åï¼Œæ‰€æœ‰é—®é¢˜éƒ½ä¼šæœç´¢")
                print()
                continue
            
            # å›ç­”é—®é¢˜
            print()
            if force_search:
                # å¼ºåˆ¶æœç´¢
                result = agent._search_web(user_input)
                if result.get("success"):
                    print(result["summary"])
                else:
                    print(f"æœç´¢å¤±è´¥ï¼Œä½¿ç”¨æ¨¡å‹çŸ¥è¯†å›ç­”ï¼š\n{agent.chat(user_input)}")
            else:
                # æ™ºèƒ½åˆ¤æ–­
                answer = agent.answer_with_search(user_input)
                print(answer)
            print()
                
        except KeyboardInterrupt:
            print("\n\nå†è§ï¼ğŸ‘‹")
            break
        except Exception as e:
            logger.error(f"é”™è¯¯: {e}")
            print(f"\nâŒ é”™è¯¯: {e}\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºå‹ AI åŠ©æ‰‹ CLI")
    parser.add_argument(
        "--config",
        default="config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--command",
        help="ç›´æ¥æ‰§è¡Œå‘½ä»¤ï¼ˆéäº¤äº’æ¨¡å¼ï¼‰"
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("åˆå§‹åŒ–å¢å¼ºå‹ AI åŠ©æ‰‹...")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    ollama_config = config.get("ollama", {})
    llm = OllamaClient(
        host=ollama_config.get("host", "http://localhost:11434"),
        model=ollama_config.get("model", "qwen2.5:32b")
    )
    
    # æ£€æŸ¥è¿æ¥
    print("\næ£€æŸ¥ Ollama è¿æ¥...")
    if not llm.check_connection():
        print("âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡")
        print("è¯·ç¡®ä¿ Ollama å·²å¯åŠ¨")
        return
    print("âœ… Ollama è¿æ¥æˆåŠŸ")
    
    # æ£€æŸ¥æ¨¡å‹
    models = llm.list_models()
    if models:
        print(f"âœ… å¯ç”¨æ¨¡å‹: {', '.join(models)}")
    
    # åˆ›å»ºå¢å¼ºå‹æ™ºèƒ½ä½“
    print("\nåˆ›å»ºå¢å¼ºå‹æ™ºèƒ½ä½“...")
    try:
        agent = WebEnhancedAgent(llm)
        print("âœ… æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
        print("âœ… ç½‘ç»œæœç´¢åŠŸèƒ½å·²å¯ç”¨")
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ™ºèƒ½ä½“å¤±è´¥: {e}")
        return
    
    # æ‰§è¡Œæ¨¡å¼
    if args.command:
        # å•å‘½ä»¤æ¨¡å¼
        print(f"\né—®é¢˜: {args.command}")
        answer = agent.answer_with_search(args.command)
        print(f"\nå›ç­”:\n{answer}")
    else:
        # äº¤äº’æ¨¡å¼
        interactive_mode(agent)


if __name__ == "__main__":
    main()
