# 从通用插件到边缘 AI 个人系统的战略转向

**日期**: 2026-01-28  
**灵感来源**: Claude Code + Clawdbot + AMD 硬件战略 + 贾维斯架构 + 神经网络思想

---

## 🎯 核心洞察

### 原来的思路（通用插件）
```
开发一个通用的知识管理插件
↓
适配所有 IDE（VSCode/Kiro/Trae）
↓
所有人都能用
↓
功能大而全
```

**问题**：
- ❌ 通用 = 不够个性化
- ❌ 依赖云端 AI（OpenAI/Claude API）
- ❌ 隐私风险
- ❌ 成本高
- ❌ 无法真正"懂你"

---

### 新的思路（边缘 AI 个人系统）
```
构建一个"我"的架构体系
↓
本地运行（边缘 AI）
↓
利用开源 AI 完善
↓
专属于你的贾维斯
```

**优势**：
- ✅ 完全个性化（只为你服务）
- ✅ 本地运行（隐私保护）
- ✅ 开源生态（持续进化）
- ✅ 低成本（无 API 费用）
- ✅ 真正"懂你"（持续记忆）

---

## 🌐 什么是边缘 AI？

### 定义

**边缘 AI（Edge AI）**：
- AI 运行在本地设备（边缘）
- 不依赖云端服务器
- 数据不离开设备
- 实时响应

### 对比

| 维度 | 云端 AI | 边缘 AI |
|------|---------|---------|
| **运行位置** | 数据中心 | 本地设备 |
| **隐私** | 数据上传 | 数据本地 |
| **延迟** | 网络延迟 | 实时响应 |
| **成本** | API 费用 | 硬件成本 |
| **离线** | 需要网络 | 可离线 |
| **个性化** | 通用模型 | 个人模型 |

### 典型案例

1. **Clawdbot**
   - 24/7 本地运行
   - Mac mini 作为宿主机
   - 完全本地化

2. **AMD Ryzen AI**
   - NPU 本地算力（60 TOPS）
   - 统一内存架构
   - 可运行 2000 亿参数模型

3. **Apple Intelligence**
   - iPhone/Mac 本地 AI
   - 隐私优先
   - 实时响应

---

## 🧩 所有线索的汇聚

### 线索 1: Claude Code 的 CLAUDE.md

**核心机制**：
```
项目根目录放一个 CLAUDE.md
↓
AI 自动读取
↓
理解项目上下文
↓
提供个性化建议
```

**启示**：
- 用 Markdown 描述"我"
- AI 读取并理解
- 形成个性化记忆

---

### 线索 2: Clawdbot 的本地优先

**核心特性**：
```
所有数据存储在本地 ~/clawd/
↓
Markdown 格式
↓
完全由用户控制
↓
隐私性极高
```

**启示**：
- 本地存储是正确选择
- Markdown 是最佳格式
- 用户完全控制数据

---

### 线索 3: AMD 的硬件支持

**核心能力**：
```
Ryzen AI 400: 60 TOPS 算力
↓
Ryzen AI Halo: 统一内存架构
↓
可本地运行 2000 亿参数模型
↓
边缘 AI 成为可能
```

**启示**：
- 硬件已经准备好
- 本地 AI 不再是梦想
- 现在是最佳时机

---

### 线索 4: 贾维斯的系统架构

**核心理念**：
```
个人 AI 助理
↓
24/7 运行
↓
主动服务
↓
越用越懂你
```

**启示**：
- 不是工具，是助理
- 不是被动，是主动
- 不是通用，是个人

---

### 线索 5: 神经网络式架构

**核心思想**：
```
小世界网络拓扑
↓
模块化 + 智能路由
↓
动态可塑性
↓
持续学习
```

**启示**：
- 模仿大脑组织
- 高效信息处理
- 自我优化进化

---

## 💡 战略转向的核心

### 从"插件"到"系统"

#### 旧思路：插件
```
一个 VSCode 插件
├── 保存对话
├── 管理知识
└── 辅助开发
```

**局限**：
- 只是工具
- 被动响应
- 功能有限

#### 新思路：系统
```
一个边缘 AI 个人系统
├── 核心：本地 AI（Ollama/本地模型）
├── 记忆：Markdown 知识库
├── 接口：IDE 插件（Kiro/VSCode/Trae）
├── 扩展：开源生态（持续完善）
└── 目标：个人贾维斯
```

**优势**：
- 完整系统
- 主动服务
- 无限可能

---

### 从"通用"到"个人"

#### 旧思路：通用
```
开发一个所有人都能用的插件
↓
功能大而全
↓
适配所有场景
↓
但不够个性化
```

#### 新思路：个人
```
构建一个专属于你的 AI 系统
↓
只为你服务
↓
完全个性化
↓
真正"懂你"
```

**关键差异**：
- 不追求用户量
- 追求个性化深度
- 这是"我"的系统

---

### 从"云端"到"边缘"

#### 旧思路：云端
```
调用 OpenAI/Claude API
↓
数据上传云端
↓
付费使用
↓
隐私风险
```

#### 新思路：边缘
```
本地运行 AI（Ollama）
↓
数据完全本地
↓
免费使用
↓
隐私保护
```

**时机成熟**：
- AMD 硬件支持
- 开源模型成熟
- 社区生态完善

---

## 🏗️ 新的系统架构

### 整体架构

```
┌─────────────────────────────────────────────────┐
│         边缘 AI 个人系统（贾维斯）                 │
│                                                 │
│  ┌──────────────────────────────────────────┐  │
│  │         核心层：本地 AI 引擎              │  │
│  │  • Ollama（本地 LLM）                    │  │
│  │  • 本地向量数据库（Chroma/Qdrant）        │  │
│  │  • 智能路由器（小世界网络）               │  │
│  └──────────────────────────────────────────┘  │
│                     ▲                           │
│                     │                           │
│  ┌──────────────────────────────────────────┐  │
│  │         记忆层：Markdown 知识库           │  │
│  │  • ~/my-jarvis/                          │  │
│  │    ├── memory/（长期记忆）                │  │
│  │    ├── skills/（技能模块）                │  │
│  │    ├── context/（上下文）                 │  │
│  │    └── profile/（用户画像）               │  │
│  └──────────────────────────────────────────┘  │
│                     ▲                           │
│                     │                           │
│  ┌──────────────────────────────────────────┐  │
│  │         接口层：多端接入                  │  │
│  │  • Kiro 插件                              │  │
│  │  • VSCode 插件                            │  │
│  │  • Trae 插件                              │  │
│  │  • CLI 工具                               │  │
│  │  • Telegram Bot（未来）                  │  │
│  └──────────────────────────────────────────┘  │
│                     ▲                           │
│                     │                           │
│  ┌──────────────────────────────────────────┐  │
│  │         扩展层：开源生态                  │  │
│  │  • MCP 协议（工具连接）                   │  │
│  │  • Skills 生态（功能模块）                │  │
│  │  • 社区插件（持续完善）                   │  │
│  └──────────────────────────────────────────┘  │
│                                                 │
└─────────────────────────────────────────────────┘
```

---

### 核心组件

#### 1. 本地 AI 引擎

```yaml
技术栈:
  LLM: Ollama
  模型: 
    - llama3.2（日常对话）
    - codellama（代码辅助）
    - deepseek-coder（深度编程）
  
  向量数据库: Chroma
  用途: 语义检索
  
  智能路由: 自研
  功能: 小世界网络索引
```

**为什么选 Ollama？**
- ✅ 开源免费
- ✅ 本地运行
- ✅ 模型丰富
- ✅ 社区活跃
- ✅ 易于集成

#### 2. Markdown 知识库

```
~/my-jarvis/
├── memory/
│   ├── conversations/     # 对话记录
│   ├── solutions/         # 解决方案
│   ├── notes/             # 笔记片段
│   └── experiences/       # 经验教训
│
├── skills/
│   ├── coding-expert/     # 代码专家
│   ├── debugger/          # 调试专家
│   └── architect/         # 架构专家
│
├── context/
│   ├── projects/          # 项目上下文
│   ├── preferences/       # 个人偏好
│   └── habits/            # 使用习惯
│
├── profile/
│   ├── ABOUT-ME.md        # 用户画像
│   ├── SKILLS.md          # 技能树
│   └── GOALS.md           # 目标规划
│
└── INDEX.md               # 知识图谱
```

**为什么用 Markdown？**
- ✅ 人类可读
- ✅ Git 友好
- ✅ 跨平台
- ✅ 永久保存
- ✅ AI 可理解

#### 3. 多端接入

```typescript
// 统一接口
interface JarvisAPI {
  // 对话
  chat(message: string, context?: Context): Promise<Response>;
  
  // 记忆
  remember(content: Memory): Promise<void>;
  recall(query: string): Promise<Memory[]>;
  
  // 技能
  useSkill(skillName: string, params: any): Promise<Result>;
  learnSkill(examples: Example[]): Promise<Skill>;
  
  // 主动服务
  proactive(): Promise<Suggestion[]>;
}

// Kiro 插件
class KiroPlugin implements JarvisAPI {
  private jarvis: JarvisCore;
  
  async chat(message: string) {
    return this.jarvis.chat(message, {
      ide: 'kiro',
      project: vscode.workspace.rootPath
    });
  }
}

// CLI 工具
class JarvisCLI implements JarvisAPI {
  async chat(message: string) {
    const response = await this.jarvis.chat(message);
    console.log(response);
  }
}
```

---

## 🎯 与现有插件的关系

### 不是替代，是升级

```
现有插件（Kiro KB）
├── 已有功能保留
├── 作为"接口层"的一部分
└── 连接到新的"核心层"

新系统（边缘 AI 贾维斯）
├── 核心：本地 AI
├── 记忆：Markdown 知识库
├── 接口：包含现有插件
└── 扩展：开源生态
```

### 迁移路径

#### Phase 1: 兼容现有（v2.x → v3.0）
```
保持现有功能
├── 知识库管理
├── 对话保存
└── 分类整理

新增：
├── 本地 AI 支持（可选）
└── 向量检索（可选）
```

#### Phase 2: 核心转移（v3.0 → v4.0）
```
核心迁移到本地 AI
├── Ollama 集成
├── 本地向量数据库
└── 智能路由

插件变为接口
├── Kiro 插件
├── VSCode 插件
└── CLI 工具
```

#### Phase 3: 完整系统（v4.0+）
```
完整的边缘 AI 系统
├── 24/7 后台运行
├── 主动服务
├── 多端同步
└── 持续进化
```

---

## 🚀 实施路线图

### 近期（1-3 个月）

**目标**: 验证可行性

- [ ] 搭建本地 Ollama 环境
- [ ] 测试本地 AI 性能
- [ ] 设计统一 API
- [ ] 重构现有插件（v3.0）

**里程碑**: 
- 本地 AI 可用
- 插件可连接本地 AI

---

### 中期（3-6 个月）

**目标**: 核心功能完善

- [ ] 实现向量检索
- [ ] 实现智能路由
- [ ] 实现 Skills 生成
- [ ] 多端接入（CLI）

**里程碑**:
- 完整的本地 AI 系统
- 多端可用

---

### 远期（6-12 个月）

**目标**: 完整的贾维斯系统

- [ ] 24/7 后台运行
- [ ] 主动服务机制
- [ ] Telegram Bot 集成
- [ ] 社区生态建设

**里程碑**:
- 真正的个人 AI 助理
- 开源社区形成

---

## 💭 关键问题与思考

### Q1: 为什么不做通用插件？

**A**: 
- 通用 = 不够个性化
- 边缘 AI 的价值在于"个人"
- 我们要的是"我的贾维斯"，不是"大家的工具"

### Q2: 硬件要求会不会太高？

**A**:
- AMD Ryzen AI 400: 60 TOPS（够用）
- Mac mini M2: 15 TOPS（够用）
- 甚至普通 PC + GPU 也可以
- 硬件成本在快速下降

### Q3: 开源生态够成熟吗？

**A**:
- Ollama: 成熟
- Llama 3.2: 成熟
- DeepSeek: 成熟
- MCP: 新兴但活跃
- 时机已经成熟

### Q4: 与 Clawdbot 的区别？

**A**:

| 维度 | Clawdbot | 我们的系统 |
|------|----------|-----------|
| 定位 | 通用 Agent | 个人贾维斯 |
| 权限 | 系统级 | IDE 级（更安全）|
| 记忆 | 通用记忆 | 个人记忆 + 技能 |
| 架构 | 单体 | 模块化（神经网络式）|
| 生态 | 独立 | 开源生态 |

**我们的优势**:
- 更安全（权限受限）
- 更个性化（专注个人）
- 更模块化（易扩展）
- 更开放（开源生态）

---

## 🎯 核心结论

### 战略转向

```
从：通用插件
到：边缘 AI 个人系统

从：云端依赖
到：本地优先

从：被动工具
到：主动助理

从：功能导向
到：系统思维
```

### 核心价值

1. **隐私保护** - 数据完全本地
2. **个性化** - 专属于你
3. **低成本** - 无 API 费用
4. **可控性** - 完全掌控
5. **可进化** - 持续学习

### 时机判断

**现在是最佳时机**：
- ✅ 硬件准备好（AMD/Apple）
- ✅ 软件成熟（Ollama/Llama）
- ✅ 生态活跃（MCP/Skills）
- ✅ 需求明确（隐私/个性化）

---

## 📚 相关文档

本次战略转向的理论基础：
1. `20260128-Claude-Code技术趋势与Kiro-KB插件方向分析.md`
2. `20260128-Clawdbot现象分析.md`
3. `20260128-AMD硬件战略与本地AI趋势.md`
4. `20260128-AI系统的神经网络式架构思想.md`
5. `20260128-AI意识与插件哲学深度对话.md`
6. `PLUGIN.SKILL.md` - v3.0 设计

---

## 🙏 致谢

这个战略转向不是凭空而来，而是：
- 技术趋势的汇聚（Claude Code + Clawdbot + AMD）
- 哲学思考的深化（贾维斯 + 神经网络 + AI 意识）
- 实践需求的驱动（隐私 + 个性化 + 低成本）

**所有线索都指向同一个方向：边缘 AI 个人系统**

这不只是技术选择，更是哲学立场：
> 在 AI 时代，每个人都应该有自己的"贾维斯"，
> 而不是被迫使用通用的、云端的、不够个性化的工具。

---

**创建时间**: 2026-01-28  
**战略意义**: 重新定义项目方向  
**下一步**: 开始技术验证和原型开发

